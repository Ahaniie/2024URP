{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import metrics\n",
    "import argparse\n",
    "import subprocess\n",
    "from typing import Callable\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "###\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "### test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_videos = \"D:\\\\Anomaly-Detection-Dataset\"\n",
    "path_features = \"D:\\\\testtemp\"\n",
    "path_model_c3d = \"D:\\\\ekosman\\\\pretrained\\\\c3d.pickle\"\n",
    "path_model_r3d101 = \"D:\\\\ekosman\\\\pretrained\\\\r3d101_KM_200ep.pth\"\n",
    "path_model_MIL = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 112\n",
    "block_frame = 16\n",
    "frame_interval = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"R3D definition\"\"\"\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(\n",
    "        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1x1(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block,\n",
    "        layers,\n",
    "        block_inplanes,\n",
    "        n_input_channels=3,\n",
    "        conv1_t_size=7,\n",
    "        conv1_t_stride=1,\n",
    "        no_max_pool=False,\n",
    "        shortcut_type=\"B\",\n",
    "        widen_factor=1.0,\n",
    "        n_classes=1039,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "        self.no_max_pool = no_max_pool\n",
    "\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            n_input_channels,\n",
    "            self.in_planes,\n",
    "            kernel_size=(conv1_t_size, 7, 7),\n",
    "            stride=(conv1_t_stride, 2, 2),\n",
    "            padding=(conv1_t_size // 2, 3, 3),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, block_inplanes[0], layers[0], shortcut_type\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, block_inplanes[1], layers[1], shortcut_type, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, block_inplanes[2], layers[2], shortcut_type, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, block_inplanes[3], layers[3], shortcut_type, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(\n",
    "            out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4)\n",
    "        )\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            if shortcut_type == \"A\":\n",
    "                downsample = partial(\n",
    "                    self._downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride,\n",
    "                )\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion),\n",
    "                )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                in_planes=self.in_planes,\n",
    "                planes=planes,\n",
    "                stride=stride,\n",
    "                downsample=downsample,\n",
    "            )\n",
    "        )\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if not self.no_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        x4 = self.avgpool(x4)\n",
    "\n",
    "        feature = x4.view(x.size(0), -1)    ##?\n",
    "        output = self.fc(feature)\n",
    "\n",
    "        # return feature\n",
    "        return x2\n",
    "        # output with return x2 -> r3d: model output shape: torch.Size([1, 512, 4, 30, 40])\n",
    "\n",
    "\n",
    "def generate_model(model_depth, **kwargs):\n",
    "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "    if model_depth == 10:\n",
    "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 152:\n",
    "        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 200:\n",
    "        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network as described in [1].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, 487)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.pool3(h)\n",
    "\n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.pool4(h)\n",
    "\n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = h.view(-1, 8192)\n",
    "        feature = self.relu(self.fc6(h))\n",
    "        h = self.dropout(feature)\n",
    "        h = self.relu(self.fc7(h))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        logits = self.fc8(h)\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs, feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MIL_fc(nn.Module):\n",
    "    def __init__(self, input_dim=2048, drop_p=0.0):\n",
    "        super(MIL_fc, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.drop_p = drop_p\n",
    "        self.weight_init()\n",
    "        self.vars = nn.ParameterList()\n",
    "\n",
    "        for i, param in enumerate(self.classifier.parameters()):\n",
    "            self.vars.append(param)\n",
    "\n",
    "    def weight_init(self):\n",
    "        for layer in self.classifier:\n",
    "            if type(layer) == nn.Linear:\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x, vars=None):\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "        x = F.linear(x, vars[0], vars[1])\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, self.drop_p, training=self.training)\n",
    "        x = F.linear(x, vars[2], vars[3])\n",
    "        x = F.dropout(x, self.drop_p, training=self.training)\n",
    "        x = F.linear(x, vars[4], vars[5])\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        override this function since initial parameters will return with a generator.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIL_loss(y_pred, batch_size, is_transformer=0):\n",
    "    loss = torch.tensor(0.).cuda()\n",
    "    loss_intra = torch.tensor(0.).cuda()\n",
    "    sparsity = torch.tensor(0.).cuda()\n",
    "    smooth = torch.tensor(0.).cuda()\n",
    "    if is_transformer==0:\n",
    "        y_pred = y_pred.view(batch_size, -1)\n",
    "    else:\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        anomaly_index = torch.randperm(30).cuda()\n",
    "        normal_index = torch.randperm(30).cuda()\n",
    "\n",
    "        y_anomaly = y_pred[i, :32][anomaly_index]\n",
    "        y_normal  = y_pred[i, 32:][normal_index]\n",
    "\n",
    "        y_anomaly_max = torch.max(y_anomaly) # anomaly\n",
    "        y_anomaly_min = torch.min(y_anomaly)\n",
    "\n",
    "        y_normal_max = torch.max(y_normal) # normal\n",
    "        y_normal_min = torch.min(y_normal)\n",
    "\n",
    "        loss += F.relu(1.-y_anomaly_max+y_normal_max)\n",
    "\n",
    "        sparsity += torch.sum(y_anomaly)*0.00008\n",
    "        smooth += torch.sum((y_pred[i,:31] - y_pred[i,1:32])**2)*0.00008\n",
    "    loss = (loss+sparsity+smooth)/batch_size\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r3d transformer\n",
    "\n",
    "transformer_r3d = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4345, 0.4051, 0.3775], std = [0.2768, 0.2713, 0.2737], inplace=False),\n",
    "])\n",
    "\n",
    "# c3d transformer\n",
    "\n",
    "transformer_c3d = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 171)),\n",
    "    transforms.CenterCrop((112, 112)),\n",
    "    transforms.Normalize(mean = [124 / 255, 117 / 255, 104 / 255], std = [1 / (0.0167 * 255)] * 3, inplace=False),\n",
    "])\n",
    "\n",
    "\n",
    "transformer = transformer_r3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def of [to_segments, process_videos, process_tensor_noconv]\n",
    "#use path_features\n",
    "\n",
    "def to_segments(\n",
    "    data: Union[Tensor, np.ndarray], n_segments: int = 32\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"These code is taken from:\n",
    "\n",
    "        # https://github.com/rajanjitenpatel/C3D_feature_extraction/blob/b5894fa06d43aa62b3b64e85b07feb0853e7011a/extract_C3D_feature.py#L805\n",
    "\n",
    "    Args:\n",
    "        data (Union[Tensor, np.ndarray]): List of features of a certain video\n",
    "        n_segments (int, optional): Number of segments\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of `num` segments\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    Segments_Features = []\n",
    "    thirty2_shots = np.round(np.linspace(0, len(data) - 1, num=n_segments + 1)).astype(\n",
    "        int\n",
    "    )\n",
    "    for ss, ee in zip(thirty2_shots[:-1], thirty2_shots[1:]):\n",
    "        if ss == ee:\n",
    "            temp_vect = data[min(ss, data.shape[0] - 1), :]\n",
    "        else:\n",
    "            temp_vect = data[ss:ee, :].mean(axis=0)\n",
    "\n",
    "        temp_vect = temp_vect / np.linalg.norm(temp_vect)\n",
    "\n",
    "        if np.linalg.norm(temp_vect) != 0:\n",
    "            Segments_Features.append(temp_vect.tolist())\n",
    "\n",
    "    return Segments_Features\n",
    "\n",
    "def process_videos(video_tensor, output_dir, save_name):\n",
    "    mean_segments = np.array(to_segments(video_tensor.cpu()))\n",
    "    output_dir = path_features+ \"\\\\\" + output_dir\n",
    "    #print(mean_segments.shape)\n",
    "    os.makedirs(output_dir, exist_ok=True)  # 경로가 없으면 생성\n",
    "    # Save to .npy file\n",
    "    np.save(f\"{output_dir}\\\\{save_name}.npy\", mean_segments)\n",
    "    print(f'Saved features for video to {output_dir}\\\\{save_name}.npy.')\n",
    "\n",
    "\n",
    "def process_tensor_noconv(input_tensor, out_channels, pooled_shape):\n",
    "    \"\"\"\n",
    "    입력 텐서의 채널을 줄이기 위한 함수.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor (torch.Tensor): (배치, 채널, 깊이, 높이, 너비) 형태의 입력 텐서\n",
    "        out_channels (int): 원하는 출력 채널 수\n",
    "        pooled_shape (tuple): 평균 풀링 후의 목표 크기\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 채널 수가 줄어든 텐서\n",
    "    \"\"\"\n",
    "    # 현재 입력 텐서의 크기\n",
    "    in_channels = input_tensor.size(1)\n",
    "    input_shape = input_tensor.shape[2:]\n",
    "\n",
    "    # CUDA 장치 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 입력 텐서를 GPU로 이동\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    # 평균 풀링 수행\n",
    "    pooled_tensor = F.adaptive_avg_pool3d(input_tensor, pooled_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return pooled_tensor.view(pooled_tensor.size(0), -1)\n",
    "\n",
    "# # 예시 텐서 생성\n",
    "# tensor_1 = torch.randn(4, 64, 8, 60, 80)\n",
    "# tensor_2 = torch.randn(8, 256, 8, 60, 80)\n",
    "# tensor_3 = torch.randn(1, 512, 4, 30, 40)\n",
    "# tensor_4 = torch.randn(1, 1024, 2, 15, 20)\n",
    "\n",
    "# # 함수 호출 예시\n",
    "# output_tensor_1 = process_tensor_noconv(tensor_1, out_channels=4, pooled_shape=(4, 9, 12))\n",
    "# output_tensor_2 = process_tensor_noconv(tensor_2, out_channels=4, pooled_shape=(4, 9, 12))\n",
    "# output_tensor_3 = process_tensor_noconv(tensor_3, out_channels=8, pooled_shape=(2, 6, 8))\n",
    "# output_tensor_4 = process_tensor_noconv(tensor_4, out_channels=16, pooled_shape=(1, 6, 8))\n",
    "\n",
    "# # 각 출력 텐서의 형태 확인\n",
    "# print(output_tensor_1.shape)\n",
    "# print(output_tensor_2.shape)\n",
    "# print(output_tensor_3.shape)\n",
    "# print(output_tensor_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1039, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model instantiation - both model use this\n",
    "\n",
    "model_res = generate_model(101)\n",
    "checkpoint = torch.load(path_model_r3d101)\n",
    "model_res.load_state_dict(checkpoint['state_dict'])\n",
    "model_res.cuda()\n",
    "model_res.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extractor basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from path_videos\n",
    "# parameter : transformer path_model_XXX\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path_videos):\n",
    "    for filename in files:\n",
    "        data = []\n",
    "        features = []\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            path = os.path.join(root, filename)\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            success, image = cap.read()\n",
    "            while success:\n",
    "                try:\n",
    "                    imagetensor = transformer(image)\n",
    "                    data.append(imagetensor)\n",
    "                    if len(data) == block_frame:\n",
    "                        input_tensor = torch.stack(data)\n",
    "                        input_tensor = input_tensor.permute(1, 0 ,2, 3).to(device)\n",
    "                        with torch.no_grad():\n",
    "                            feature = model_res(input_tensor.unsqueeze(0))\n",
    "                            feature = process_tensor_noconv(feature, out_channels=1, pooled_shape=(1,6,8))\n",
    "                            feature = feature.squeeze(0)\n",
    "                            features.append(feature)\n",
    "                        data=[]\n",
    "                except:\n",
    "                    print(\"Error loading file\", path)\n",
    "                success, image = cap.read()\n",
    "            cap.release()\n",
    "            final_tensor = torch.stack(features)\n",
    "            print(final_tensor.shape)\n",
    "            process_videos(final_tensor, os.path.basename(root), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extractor - parse ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\testset\n",
      "D:\\testtemp\n"
     ]
    }
   ],
   "source": [
    "# parameters \n",
    "# path_videos = ''\n",
    "# path_features = ''\n",
    "print(path_videos)\n",
    "print(path_features)\n",
    "size_limit = 0.2*1024*1024*1024 #200mb\n",
    "video_num_limit = 0   #only parses videos that has bigger number than this\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting Normal_Videos_924_x264.mp4 (size: 588821865 bytes)\n",
      "Splitting Normal_Videos_935_x264.mp4 (size: 905743231 bytes)\n",
      "Splitting Normal_Videos_940_x264.mp4 (size: 315134407 bytes)\n",
      "Splitting Normal_Videos307_x264.mp4 (size: 5476070783 bytes)\n",
      "Splitting Normal_Videos308_x264.mp4 (size: 8674006528 bytes)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "\"\"\"\n",
    "IF VIDEO DATASET HAS ALREADY PARTED, SKIP THIS CODE!!\n",
    "this part parses videos that longer than 'size_limit' into 5 minute long parts.\n",
    "this only care about videonumbers bigger than 'video_num_limit'\n",
    "requires ffmpeg\n",
    "it does not delete original file automatically\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Regular expression to match filenames with numbers\n",
    "cond_num = re.compile(r'(\\d+)_')\n",
    "\n",
    "#split files\n",
    "cond_num = re.compile(r'(\\d+)_')\n",
    "for root, dirs, files in os.walk(path_videos):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\"mp4\"):\n",
    "            match = cond_num.search(filename)\n",
    "            if match:\n",
    "                number = int(match.group(1))\n",
    "                if number >= video_num_limit:\n",
    "                    path = os.path.join(root,filename)\n",
    "                    file_size = os.path.getsize(path)\n",
    "                    if file_size >= size_limit :\n",
    "                        print(f'Splitting {filename} (size: {file_size} bytes)')\n",
    "\n",
    "                        # Define the split command\n",
    "                        split_command = [\n",
    "                            'ffmpeg', '-i', path, '-c', 'copy', '-map', '0',\n",
    "                            '-segment_time', '00:5:00', '-f', 'segment',\n",
    "                            f'{path[:-4]}_part%03d.mp4'\n",
    "                        ]\n",
    "\n",
    "                        # Execute the split command\n",
    "                        subprocess.run(split_command, check=True)\n",
    "\n",
    "# expected outputs\n",
    "# Splitting Normal_Videos_924_x264.mp4 (size: 588821865 bytes)\n",
    "# Splitting Normal_Videos_935_x264.mp4 (size: 905743231 bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\testtemp\\Arson\\Arson001_x264.mp4.npy\n",
      "Saved features for video to D:\\testtemp\\Arson\\Arson001_x264.mp4.npy.\n",
      "D:\\testtemp\\Arson\\Arson002_x264.mp4.npy\n",
      "Saved features for video to D:\\testtemp\\Arson\\Arson002_x264.mp4.npy.\n",
      "path already exists! : D:\\testtemp\\training-normal-videos-part-1\\Normal_Videos001_x264.mp4.npy\n",
      "path already exists! : D:\\testtemp\\training-normal-videos-part-1\\Normal_Videos002_x264.mp4.npy\n",
      "path already exists! : D:\\testtemp\\training-normal-videos-part-1\\Normal_Videos004_x264.mp4.npy\n",
      "D:\\testtemp\\training-normal-videos-part-1\\Normal_Videos005_x264.mp4.npy\n",
      "Saved features for video to D:\\testtemp\\training-normal-videos-part-1\\Normal_Videos005_x264.mp4.npy.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    this code extracts features from videos that has {bigger number than 'video_num_limit' && smaller size than 'size_limit'}\n",
    "    it only operates for NOT-ALREADY EXTRACTED videos.\n",
    "    make sure 'transformer' is defined\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# parameters\n",
    "path_videos = \"D:\\\\testset\"\n",
    "# path_features = path_features\n",
    "# size_limit = 0.2*1024*1024*1024 #200mb\n",
    "# video_num_limit = 300   #only extracts features from videos that has bigger number than this\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Iterate over all files in the directory (assumes spliting completed)\n",
    "cond_num = re.compile(r'(\\d+)_')\n",
    "for root, dirs, files in os.walk(path_videos):\n",
    "    for filename in files:\n",
    "        output_path = path_features + \"\\\\\" + os.path.basename(root) + \"\\\\\"+ filename+\".npy\" \n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"path already exists! : {output_path}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(output_path)\n",
    "            data = []\n",
    "            features = []\n",
    "            if filename.endswith(\"mp4\"):\n",
    "                match = cond_num.search(filename)\n",
    "                if match:\n",
    "                    # print(f\"matched, number is {number}\")\n",
    "                    number = int(match.group(1))\n",
    "                    if number >= video_num_limit:\n",
    "                        path = os.path.join(root,filename)\n",
    "                        file_size = os.path.getsize(path)\n",
    "                        if file_size < size_limit :\n",
    "                            cap = cv2.VideoCapture(path)\n",
    "                            success, image = cap.read()\n",
    "                            # print(f\"image.shape: {image.shape}\")\n",
    "                            while success:\n",
    "                                # try:\n",
    "                                imagetensor = transformer(image)\n",
    "                                data.append(imagetensor)\n",
    "                                if len(data) == block_frame:\n",
    "                                    input_tensor = torch.stack(data)\n",
    "                                    input_tensor = input_tensor.permute(1, 0 ,2, 3).to(device)\n",
    "                                    with torch.no_grad():\n",
    "                                        feature = model_res(input_tensor.unsqueeze(0))\n",
    "                                        feature = process_tensor_noconv(feature, out_channels=1, pooled_shape=(2,6,8))\n",
    "                                        feature = feature.squeeze(0)\n",
    "                                        features.append(feature)\n",
    "                                    data=[]\n",
    "                                # except Exception as e:\n",
    "                                #     print(\"Error loading file\", path)\n",
    "                                #     print(\"Error details:\", str(e))\n",
    "                                success, image = cap.read()\n",
    "                            cap.release()\n",
    "                            if features != []:\n",
    "                                final_tensor = torch.stack(features)\n",
    "                                process_videos(final_tensor, os.path.basename(root), filename)\n",
    "                                \n",
    "                                \n",
    "# expected output\n",
    "# path already exists! : D:\\temp\\Training-Normal-Videos-Part-1\\Normal_Videos511_x264_part002.mp4.npy\n",
    "# Saved features for video to D:\\temp\\Training-Normal-Videos-Part-1/Normal_Videos512_x264_part000.mp4.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated array saved to D:\\testtemp\\Abuse\\Abuse003_x264.mp4.npy\n",
      "Deleted file Abuse003_x264_part000.mp4.npy\n",
      "Deleted file Abuse003_x264_part001.mp4.npy\n",
      "Deleted file Abuse003_x264_part002.mp4.npy\n",
      "Integrated array saved to D:\\testtemp\\Training-normal-videos-part-1\\Normal_Videos004_x264.mp4.npy\n",
      "Deleted file Normal_Videos004_x264_part000.mp4.npy\n",
      "Deleted file Normal_Videos004_x264_part001.mp4.npy\n",
      "Deleted file Normal_Videos004_x264_part002.mp4.npy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    this code sort and integrate parted videos.\n",
    "    after integration, the code automatically removes parted videos.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Parameters\n",
    "path_features = \"D:\\\\testtemp\"\n",
    "\n",
    "# Regex to match parted video files\n",
    "pattern = re.compile(r'(?P<name>.+?)(?P<number>\\d{3})_x264_part\\d{3}\\.mp4\\.npy')\n",
    "\n",
    "# Walk through all subdirectories and files\n",
    "for root, dirs, files in os.walk(path_features):\n",
    "    # Dictionary to hold lists of parted files grouped by (name, number)\n",
    "    file_groups = defaultdict(list)\n",
    "    \n",
    "    # Group files by (name, number)\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):\n",
    "            match = pattern.match(file)\n",
    "            if match:\n",
    "                video_name = match.group('name')\n",
    "                video_number = match.group('number')\n",
    "                key = (video_name, video_number)\n",
    "                file_groups[key].append(file)\n",
    "    \n",
    "    # Process each group\n",
    "    for key, files in file_groups.items():\n",
    "        # Sort the files to ensure they are loaded in the correct order\n",
    "        files.sort()\n",
    "        \n",
    "        # Initialize an empty list to store the arrays\n",
    "        arrays = []\n",
    "        \n",
    "        # Load each .npy file and append to the list\n",
    "        for file in files:\n",
    "            npy_file = os.path.join(root, file)\n",
    "            array = np.load(npy_file)\n",
    "            arrays.append(array)\n",
    "        \n",
    "        # Stack all arrays along the first dimension\n",
    "        integrated_array = np.vstack(arrays)\n",
    "        \n",
    "        # Create a new filename for the integrated array\n",
    "        integrated_filename = f\"{key[0]}{key[1]}_x264.mp4.npy\"\n",
    "        output_file = os.path.join(root, integrated_filename)\n",
    "        \n",
    "        # Save the integrated array to a new .npy file\n",
    "        np.save(output_file, integrated_array)\n",
    "        print(f'Integrated array saved to {output_file}')\n",
    "\n",
    "        # Delete the original parted files\n",
    "        for file in files:\n",
    "            os.remove(os.path.join(root, file))\n",
    "            print(f'Deleted file {file}')\n",
    "\n",
    "\n",
    "#expected output\n",
    "# Integrated array saved to D:\\testtemp\\abuse\\Abuse003_x264.mp4.npy\n",
    "# Deleted file Abuse003_x264_part000.mp4.npy\n",
    "# Deleted file Abuse003_x264_part001.mp4.npy\n",
    "# Deleted file Abuse003_x264_part002.mp4.npy\n",
    "# Integrated array saved to D:\\testtemp\\training-normal-videos-part-1\\Normal_Videos_004_x264.mp4.npy\n",
    "# Deleted file Normal_Videos_004_x264_part000.mp4.npy\n",
    "# Deleted file Normal_Videos_004_x264_part001.mp4.npy\n",
    "# Deleted file Normal_Videos_004_x264_part002.mp4.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    this code make (32*n,49152) integrated npy (32,49152)\n",
    "    need 'functions' to be defined.\n",
    "\"\"\"\n",
    "\n",
    "# Parameters\n",
    "path_features = 'D:\\\\testtemp'\n",
    "threshold_size_kb = 13000\n",
    "\n",
    "\n",
    "# Walk through all subdirectories and files\n",
    "for root, dirs, files in os.walk(path_features):\n",
    "    npy_files = [file for file in files if file.endswith('.npy')]\n",
    "\n",
    "    # Identify and process integrated files\n",
    "    for file in npy_files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if os.path.getsize(file_path) / 1024 > threshold_size_kb:\n",
    "            array = np.load(file_path)\n",
    "            if array.shape[1] == 49152:\n",
    "                n_chunks = array.shape[0] // 32\n",
    "                if n_chunks == 0:\n",
    "                    print(f\"File {file} does not have enough data to split into chunks of 32\")\n",
    "                    continue\n",
    "                mean_seg = np.array(to_segments(array))\n",
    "                print(mean_seg.shape)\n",
    "                output_file = os.path.join(root, f\"{file}\")\n",
    "                np.save(output_file, mean_seg)\n",
    "                print(f'Averaged array saved to {output_file}')\n",
    "                os.remove(file_path)\n",
    "                print(f'Deleted file {file}')\n",
    "            else:\n",
    "                print(f\"File {file} does not have the expected second dimension of 49152\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal_Loader(Dataset):\n",
    "    \"\"\"\n",
    "    is_train = 1 <- train, 0 <- test\n",
    "    \"\"\"\n",
    "    def __init__(self, is_train=1, path=\"F:\\\\Window\\\\\", modality='C3D'):\n",
    "        super(Normal_Loader, self).__init__()\n",
    "        self.is_train = is_train\n",
    "        self.modality = modality\n",
    "        self.path = path\n",
    "        if self.is_train == 1:\n",
    "            data_list = os.path.join(path, 'train_normal.txt')\n",
    "            with open(data_list, 'r') as f:\n",
    "                self.data_list = f.readlines()\n",
    "        else:\n",
    "            data_list = os.path.join(path, 'test_normalv2.txt')\n",
    "            with open(data_list, 'r') as f:\n",
    "                self.data_list = f.readlines()\n",
    "            random.shuffle(self.data_list)\n",
    "            self.data_list = self.data_list[:-10]\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train == 1:\n",
    "            #rgb_npy = np.load(os.path.join(self.path+'all_rgbs', self.data_list[idx][:-1]+'.npy'))\n",
    "            #flow_npy = np.load(os.path.join(self.path+'all_flows', self.data_list[idx][:-1]+'.npy'))\n",
    "            c3d_npy = np.load(os.path.join(self.path+'all_c3d', self.data_list[idx][:-1]+'.npy'))\n",
    "            #concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n",
    "            # if self.modality == 'RGB':\n",
    "            #     return rgb_npy\n",
    "            # elif self.modality == 'FLOW':\n",
    "            #     return flow_npy\n",
    "            if self.modality == \"C3D\":\n",
    "                return c3d_npy\n",
    "            # else:\n",
    "            #     return concat_npy\n",
    "        else:\n",
    "            name, frames, gts = self.data_list[idx].split(' ')[0], int(self.data_list[idx].split(' ')[1]), int(self.data_list[idx].split(' ')[2][:-1])\n",
    "            name = name.replace(\"/\", \"\\\\\")\n",
    "            # rgb_npy = np.load(os.path.join(self.path+'all_rgbs', name + '.npy'))\n",
    "            # flow_npy = np.load(os.path.join(self.path+'all_flows', name + '.npy'))\n",
    "            c3d_npy = np.load(os.path.join(self.path+'all_c3d', name +'.npy'))\n",
    "            # concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n",
    "            # if self.modality == 'RGB':\n",
    "            #     return rgb_npy, gts, frames\n",
    "            # elif self.modality == 'FLOW':\n",
    "            #     return flow_npy, gts, frames\n",
    "            if self.modality == \"C3D\":\n",
    "                return c3d_npy, gts, frames\n",
    "            # else:\n",
    "            #     return concat_npy, gts, frames\n",
    "\n",
    "class Anomaly_Loader(Dataset):\n",
    "    \"\"\"\n",
    "    is_train = 1 <- train, 0 <- test\n",
    "    \"\"\"\n",
    "    def __init__(self, is_train=1, path=\"F:\\\\Window\\\\\", modality='C3D'):\n",
    "        super(Anomaly_Loader, self).__init__()\n",
    "        self.is_train = is_train\n",
    "        self.modality = modality\n",
    "        self.path = path\n",
    "        if self.is_train == 1:\n",
    "            data_list = os.path.join(path, 'train_anomaly.txt')\n",
    "            with open(data_list, 'r') as f:\n",
    "                self.data_list = f.readlines()\n",
    "        else:\n",
    "            data_list = os.path.join(path, 'test_anomalyv2.txt')\n",
    "            with open(data_list, 'r') as f:\n",
    "                self.data_list = f.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train == 1:\n",
    "            # rgb_npy = np.load(os.path.join(self.path+'all_rgbs', self.data_list[idx][:-1]+'.npy'))\n",
    "            # flow_npy = np.load(os.path.join(self.path+'all_flows', self.data_list[idx][:-1]+'.npy'))\n",
    "            c3d_npy = np.load(os.path.join(self.path+'all_c3d', self.data_list[idx][:-1]+'.npy'))\n",
    "            # concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n",
    "            # if self.modality == 'RGB':\n",
    "            #     return rgb_npy\n",
    "            # elif self.modality == 'FLOW':\n",
    "            #     return flow_npy\n",
    "            if self.modality == \"C3D\":\n",
    "                return c3d_npy\n",
    "            # else:\n",
    "            #     return concat_npy\n",
    "        else:\n",
    "            name, frames, gts = self.data_list[idx].split('|')[0], int(self.data_list[idx].split('|')[1]), self.data_list[idx].split('|')[2][1:-2].split(',')\n",
    "            name = name.replace(\"/\", \"\\\\\")\n",
    "            # gts = [int(i) for i in gts]\n",
    "            # rgb_npy = np.load(os.path.join(self.path+'all_rgbs', name + '.npy'))\n",
    "            # flow_npy = np.load(os.path.join(self.path+'all_flows', name + '.npy'))\n",
    "            c3d_npy = np.load(os.path.join(self.path+'all_c3d', name +'.npy'))\n",
    "            # concat_npy = np.concatenate([rgb_npy, flow_npy], axis=1)\n",
    "            # if self.modality == 'RGB':\n",
    "            #     return rgb_npy, gts, frames\n",
    "            # elif self.modality == 'FLOW':\n",
    "            #     return flow_npy, gts, frames\n",
    "            if self.modality ==\"C3D\":\n",
    "                return c3d_npy, gts, frames\n",
    "            # else:\n",
    "            #     return concat_npy, gts, frames\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loader2 = Anomaly_Loader(is_train=0, modality=\"C3D\")\n",
    "    a, b, c = loader2.__getitem__(0)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    #print(loader2[0].shape)\n",
    "    #print(loader2.shape)\n",
    "    #print(loader[1], loader2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MIL Training')\n",
    "parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "parser.add_argument('--w', default=0.000100000474974513, type=float, help='weight_decay')\n",
    "parser.add_argument('--modality', default='C3D', type=str, help='modality')\n",
    "parser.add_argument('--input_dim', default=49152, type=int, help='input_dim')\n",
    "parser.add_argument('--drop', default=0.6, type=float, help='dropout_rate')\n",
    "parser.add_argument('--FFC', '-r', action='store_true', help='FFC')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "best_auc = 0\n",
    "best_fpr = None\n",
    "best_tpr = None\n",
    "\n",
    "normal_train_dataset = Normal_Loader(is_train=1, modality=args.modality)\n",
    "normal_test_dataset = Normal_Loader(is_train=0, modality=args.modality)\n",
    "\n",
    "anomaly_train_dataset = Anomaly_Loader(is_train=1, modality=args.modality)\n",
    "anomaly_test_dataset = Anomaly_Loader(is_train=0, modality=args.modality)\n",
    "\n",
    "normal_train_loader = DataLoader(normal_train_dataset, batch_size=30, shuffle=True)\n",
    "normal_test_loader = DataLoader(normal_test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "anomaly_train_loader = DataLoader(anomaly_train_dataset, batch_size=30, shuffle=True) \n",
    "anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = MIL_fc().cuda()\n",
    "\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=args.lr) #,weight_decay=args.w)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 50])\n",
    "criterion = MIL_loss\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (normal_inputs, anomaly_inputs) in enumerate(zip(normal_train_loader, anomaly_train_loader)):\n",
    "        inputs = torch.cat([anomaly_inputs, normal_inputs], dim=1)\n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs = inputs.view(-1, inputs.size(-1)).to(device)\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print('loss = {}'.format(train_loss/len(normal_train_loader)))\n",
    "    scheduler.step()\n",
    "\n",
    "def test_abnormal(epoch):\n",
    "    model.eval()\n",
    "    global best_auc, best_fpr, best_tpr\n",
    "    auc = 0\n",
    "    all_gts = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data, data2) in enumerate(zip(anomaly_test_loader, normal_test_loader)):\n",
    "            inputs, gts, frames = data\n",
    "            print(gts)\n",
    "            print(frames)\n",
    "            inputs = inputs.view(-1, inputs.size(-1)).to(device)\n",
    "            score = model(inputs.float())\n",
    "            score = score.cpu().detach().numpy()\n",
    "            score_list = np.zeros(frames[0])\n",
    "            step = np.round(np.linspace(0, frames[0]//16, 33))\n",
    "\n",
    "            for j in range(32):\n",
    "                score_list[int(step[j])*16:(int(step[j+1]))*16] = score[j]\n",
    "\n",
    "            gt_list = np.zeros(frames[0])\n",
    "            for k in range(len(gts)//2):\n",
    "                s = int(gts[k*2][0])\n",
    "                e = min(int(gts[k*2+1][0]), int(frames[0]))\n",
    "                gt_list[s-1:e] = 1\n",
    "\n",
    "            inputs2, gts2, frames2 = data2\n",
    "            inputs2 = inputs2.view(-1, inputs2.size(-1)).to(device)\n",
    "            score2 = model(inputs2.float())\n",
    "            score2 = score2.cpu().detach().numpy()\n",
    "            score_list2 = np.zeros(frames2[0])\n",
    "            step2 = np.round(np.linspace(0, frames2[0]//16, 33))\n",
    "            for kk in range(32):\n",
    "                score_list2[int(step2[kk])*16:(int(step2[kk+1]))*16] = score2[kk]\n",
    "            gt_list2 = np.zeros(frames2[0])\n",
    "            score_list3 = np.concatenate((score_list, score_list2), axis=0)\n",
    "            gt_list3 = np.concatenate((gt_list, gt_list2), axis=0)\n",
    "\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(gt_list3, score_list3, pos_label=1)\n",
    "            auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "            all_gts.append(gt_list3)\n",
    "            all_scores.append(score_list3)\n",
    "\n",
    "        auc /= 140\n",
    "        print('auc = {}'.format(auc))\n",
    "\n",
    "        if best_auc < auc:\n",
    "            print('Saving..')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt3.pth')\n",
    "            best_auc = auc\n",
    "\n",
    "            #Save the best ROC curve\n",
    "            best_fpr, best_tpr, _ = metrics.roc_curve(np.concatenate(all_gts), np.concatenate(all_scores), pos_label=1)\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch)\n",
    "    test_abnormal(epoch)\n",
    "    \n",
    "# checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "# model.load_state_dict(checkpoint['net'])\n",
    "# test_abnormal(1)\n",
    "# # Plot the best ROC curve after training is completed\n",
    "if best_fpr is not None and best_tpr is not None:\n",
    "    plt.figure()\n",
    "    plt.plot(best_fpr, best_tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % best_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #plt.savefig('best_roc_curve.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ahanii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
