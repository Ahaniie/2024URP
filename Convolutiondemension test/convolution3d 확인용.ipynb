{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb358c9-5a8f-4aee-ab5f-1db37974d19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80caa367",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 8.710986,
     "end_time": "2024-03-18T13:10:50.998486",
     "exception": false,
     "start_time": "2024-03-18T13:10:42.287500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc08077",
   "metadata": {
    "papermill": {
     "duration": 0.008184,
     "end_time": "2024-03-18T13:10:42.279133",
     "exception": false,
     "start_time": "2024-03-18T13:10:42.270949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Stuff & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3bd6dc",
   "metadata": {
    "papermill": {
     "duration": 0.102383,
     "end_time": "2024-03-18T13:10:51.109927",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.007544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904f3382",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_LAUNCH_BLOCKING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c122a3",
   "metadata": {
    "papermill": {
     "duration": 0.015454,
     "end_time": "2024-03-18T13:10:51.134564",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.119110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESOLUTION = 64\n",
    "block_frame = 8\n",
    "frame_interval = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c4ac3",
   "metadata": {
    "papermill": {
     "duration": 0.014977,
     "end_time": "2024-03-18T13:10:51.158055",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.143078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings( \"ignore\", module = \"matplotlib\\..*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1d0f2",
   "metadata": {
    "papermill": {
     "duration": 0.015692,
     "end_time": "2024-03-18T13:10:51.183090",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.167398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    # transforms.Lambda(lambda x: x / 255.),\n",
    "    transforms.Resize((RESOLUTION, RESOLUTION))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c986f9",
   "metadata": {
    "papermill": {
     "duration": 0.008199,
     "end_time": "2024-03-18T13:10:51.199759",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.191560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ae748",
   "metadata": {
    "papermill": {
     "duration": 0.008208,
     "end_time": "2024-03-18T13:10:51.296122",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.287914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75883e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T13:10:51.314167Z",
     "iopub.status.busy": "2024-03-18T13:10:51.313885Z",
     "iopub.status.idle": "2024-03-18T13:10:51.318124Z",
     "shell.execute_reply": "2024-03-18T13:10:51.317353Z"
    },
    "papermill": {
     "duration": 0.015519,
     "end_time": "2024-03-18T13:10:51.320057",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.304538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DATA_SOURCE = {\n",
    "#     \"Abuse\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Abuse\",\n",
    "#     \"Arrest\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Arrest\",\n",
    "#     \"Arson\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Arson\",\n",
    "#     \"Assault\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Assault\",\n",
    "#     \"Burglary\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-2\\Burglary\",\n",
    "#     \"Explosion\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-2\\Explosion\",\n",
    "#     \"Fighting\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-2\\Fighting\",\n",
    "#     \"Normal\" : \"E:\\\\kaggle\\\\input\\\\crimeufcdataset\\\\Anomaly_Dataset\\\\Anomaly_Videos\\\\Normal-Videos-Part-1\"\n",
    "# }\n",
    "\n",
    "DATA_SOURCE = {\n",
    "    \"Abuse\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Abuse\",\n",
    "    \"Arrest\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Arrest\",\n",
    "    \"Arson\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Arson\",\n",
    "    \"Assault\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Assault\",\n",
    "    \"Burglary\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-2\\\\Burglary\",\n",
    "    \"Explosion\" : \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-2\\\\Explosion\",\n",
    "    \"Fighting\" : \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-2\\\\Fighting\",\n",
    "    \"RoadAccidents\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-3\\\\RoadAccidents\",\n",
    "    \"Robbery\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-3\\\\Robbery\",\n",
    "    \"Shooting\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-3\\\\Shooting\",\n",
    "    \"Shoplifting\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-4\\\\Shoplifting\",\n",
    "    \"Stealing\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-4\\\\Stealing\",\n",
    "    \"Vandalism\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-4\\\\Vandalism\",\n",
    "    \"Normal\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Training-Normal-Videos-Part-1\",\n",
    "}\n",
    "\n",
    "TEST_SOURCE = {\n",
    "    \"Normal\" : r\"E:\\kaggle\\input\\Anomaly-Detection-Dataset\\Testing_Normal_Videos_Anomaly\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# DATA_SOURCE = {\n",
    "#     \"Abuse\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Abusetest\",\n",
    "#     \"Arrest\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Arresttest\",\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855e224",
   "metadata": {},
   "source": [
    "# for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_SOURCE = {\n",
    "#     \"Abuse\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Abuse\",\n",
    "#     \"Arrest\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Arrest\",\n",
    "#     \"Arson\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Arson\",\n",
    "#     \"Assault\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-1\\Assault\",\n",
    "#     \"Burglary\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-2\\Burglary\",\n",
    "#     \"Explosion\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-2\\Explosion\",\n",
    "#     \"Fighting\": \"E:\\kaggle\\input\\crimeufcdataset\\Anomaly_Dataset\\Anomaly_Videos\\Anomaly-Videos-Part-2\\Fighting\",\n",
    "#     \"Normal\" : \"E:\\\\kaggle\\\\input\\\\crimeufcdataset\\\\Anomaly_Dataset\\\\Anomaly_Videos\\\\Normal-Videos-Part-1\"\n",
    "# }\n",
    "\n",
    "DATA_SOURCE = {\n",
    "    \"Abuse\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Abuse\",\n",
    "    \"Arrest\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Arrest\",\n",
    "    \"Arson\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Arson\",\n",
    "    \"Assault\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-1\\\\Assault\",\n",
    "    \"Burglary\": \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-2\\\\Burglary\",\n",
    "    \"Explosion\" : \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-2\\\\Explosion\",\n",
    "    \"Fighting\" : \"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-2\\\\Fighting\",\n",
    "    \"RoadAccidents\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-3\\\\RoadAccidents\",\n",
    "    \"Robbery\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-3\\\\Robbery\",\n",
    "    \"Shooting\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-3\\\\Shooting\",\n",
    "    \"Shoplifting\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-4\\\\Shoplifting\",\n",
    "    \"Stealing\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-4\\\\Stealing\",\n",
    "    \"Vandalism\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Anomaly-Videos-Part-4\\\\Vandalism\",\n",
    "    \"Normal\" :\"E:\\\\kaggle\\\\input\\\\Anomaly-Detection-Dataset\\\\Training-Normal-Videos-Part-1\",\n",
    "}\n",
    "\n",
    "# TEST_SOURCE = {\n",
    "#     \"Normal\" : r\"E:\\kaggle\\input\\Anomaly-Detection-Dataset\\Testing_Normal_Videos_Anomaly\"\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb248d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "txt_train = r\"E:\\kaggle\\input\\Anomaly-Detection-Dataset\\Anomaly_Train.txt\"\n",
    "train_dic = {}\n",
    "with open(txt_train, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split('/')\n",
    "        train_dic[parts[1]] = parts[0]\n",
    "    \n",
    "txt_test = r\"E:\\kaggle\\input\\Anomaly-Detection-Dataset\\Temporal_Anomaly_Annotation_for_Testing_Videos.txt\"\n",
    "test_dic = {}\n",
    "with open(txt_test, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        video_name = parts[0]\n",
    "        event_name = parts[1]\n",
    "        start_frame1 = int(parts[2])\n",
    "        end_frame1 = int(parts[3])\n",
    "        start_frame2 = int(parts[4])\n",
    "        end_frame2 = int(parts[5])\n",
    "        test_dic[video_name] = [event_name, start_frame1, end_frame1, start_frame2, end_frame2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3eaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "listtest = txt_test.split('\\\\')\n",
    "print(listtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 경로가 존재하는지 확인합니다.\n",
    "if os.path.exists(txt_test):\n",
    "    print(\"경로가 존재합니다.\")\n",
    "    # 디렉터리 내의 파일 목록을 출력합니다.\n",
    "else:\n",
    "    print(\"지정된 경로를 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for directory_path in TEST_SOURCE.items():\n",
    "# 경로가 존재하는지 확인합니다.\n",
    "    if os.path.exists(directory_path[1]):\n",
    "        print(\"경로가 존재합니다.\")\n",
    "        # 디렉터리 내의 파일 목록을 출력합니다.\n",
    "        print(\"디렉터리 내용:\", os.listdir(directory_path[1]))\n",
    "    else:\n",
    "        print(\"지정된 경로를 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name, start_frame1, end_frame1, start_frame2, end_frame2 = test_dic[\"\"]\n",
    "print(frame_count, start_frame1, start_frame2, end_frame1, end_frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d06374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T13:10:51.338518Z",
     "iopub.status.busy": "2024-03-18T13:10:51.338184Z",
     "iopub.status.idle": "2024-03-18T13:10:51.352085Z",
     "shell.execute_reply": "2024-03-18T13:10:51.351221Z"
    },
    "papermill": {
     "duration": 0.025363,
     "end_time": "2024-03-18T13:10:51.353938",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.328575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrimeDataset(Dataset):\n",
    "    train = True\n",
    "    def __init__(self, __train=True):\n",
    "        train = __train\n",
    "        self._data = []\n",
    "        self._labels = []\n",
    "        self._frame_interval = frame_interval\n",
    "        \n",
    "        print(f\"Loading {'train' if train else 'test' } dataset...\")\n",
    "\n",
    "        if train:\n",
    "            for label, data_path in DATA_SOURCE.items():\n",
    "                print(f\"Loading Label {label}...\")\n",
    "            \n",
    "                for file in tqdm(os.listdir(data_path)):\n",
    "                    if file.endswith(\".mp4\") and file in train_dic:\n",
    "                        path = os.path.join(data_path, file)\n",
    "                        data, labels = self._parse_file(path, label)\n",
    "                    \n",
    "                        self._data.extend(data)\n",
    "                        self._labels.extend(labels)\n",
    "        else:\n",
    "            for label, data_path in DATA_SOURCE.items():\n",
    "                print(f\"Loading Label {label}...\")\n",
    "            \n",
    "                for file in tqdm(os.listdir(data_path)):\n",
    "                    if file.endswith(\".mp4\") and file in test_dic:\n",
    "                        path = os.path.join(data_path, file)\n",
    "                        data, labels = self._parse_file(path, label)\n",
    "                \n",
    "                    \n",
    "                        self._data.extend(data)\n",
    "                        self._labels.extend(labels)\n",
    "                    \n",
    "        print(f\"Finished loading {'train' if train else 'test' } dataset... Loaded  {len(self._data)} images.\")\n",
    "    \n",
    "    def _parse_file(self, __path, __label):\n",
    "        if not os.path.exists(__path):\n",
    "            return [], []\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        cap = cv2.VideoCapture(__path)\n",
    "        \n",
    "        frames = []\n",
    "        frame_count = 0\n",
    "        success, image = cap.read()\n",
    "        while success:\n",
    "            try:\n",
    "                if True:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "                    Y, U, V = cv2.split(image)\n",
    "                    image = transformer(Y)\n",
    "                    frames.append(image)\n",
    "                    \n",
    "                    if len(frames) == block_frame:\n",
    "                        if train:\n",
    "                            stacked_frames = torch.stack(frames)\n",
    "                            stacked_frames = stacked_frames.permute(1, 0, 2, 3)\n",
    "                            data.append(stacked_frames)\n",
    "                            labels.append(__label)\n",
    "                            frames = frames[3:]\n",
    "                        else:\n",
    "                            stacked_frames = torch.stack(frames)\n",
    "                            stacked_frames = stacked_frames.permute(1, 0, 2, 3)\n",
    "                            data.append(stacked_frames)\n",
    "                            filepath_list = __path.split('\\\\')\n",
    "                            event_name, start_frame1, end_frame1, start_frame2, end_frame2 = test_dic[filepath_list[-1]]\n",
    "                            if (frame_count >= start_frame1 and frame_count <= end_frame1) or (frame_count >= start_frame2 and frame_count <= end_frame2):\n",
    "                                labels.append(__label)\n",
    "                            else:\n",
    "                                labels.append(\"Normal\")\n",
    "                            frames = frames[3:]\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {__path}: {e}\")\n",
    "            \n",
    "            count = 0\n",
    "            while success and count < self._frame_interval:\n",
    "                success, image = cap.read()\n",
    "                frame_count +=1\n",
    "                count += 1\n",
    "                \n",
    "        if len(frames) > 0 and len(frames) < block_frame:\n",
    "            while len(frames) < block_frame:\n",
    "                frames.append(frames[-1])\n",
    "            stacked_frames = torch.stack(frames)\n",
    "            stacked_frames = stacked_frames.permute(1, 0, 2, 3)\n",
    "            data.append(stacked_frames)\n",
    "            if train:\n",
    "                labels.append(__label)\n",
    "            else:\n",
    "                if (frame_count >= start_frame1 and frame_count <= end_frame1) or (frame_count >= start_frame2 and frame_count <= end_frame2):\n",
    "                    labels.append(__label)\n",
    "                else:\n",
    "                    labels.append(\"Normal\")       \n",
    "        return data, labels\n",
    "        \n",
    "    \n",
    "    def label_str2id(self, __label):\n",
    "        labels = DATA_SOURCE.keys()\n",
    "        return list(labels).index(__label)\n",
    "\n",
    "    def label_id2str(self, __label):\n",
    "        labels = DATA_SOURCE.keys()\n",
    "        return list(labels)[__label]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._labels)\n",
    "\n",
    "    def __getitem__(self, __idx):\n",
    "        data = self._data[__idx]\n",
    "        label = self._labels[__idx]\n",
    "        return data, torch.tensor([self.label_str2id(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5eab9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T13:10:51.371922Z",
     "iopub.status.busy": "2024-03-18T13:10:51.371655Z",
     "iopub.status.idle": "2024-03-18T13:21:45.090780Z",
     "shell.execute_reply": "2024-03-18T13:21:45.089667Z"
    },
    "papermill": {
     "duration": 653.730762,
     "end_time": "2024-03-18T13:21:45.093180",
     "exception": false,
     "start_time": "2024-03-18T13:10:51.362418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = True\n",
    "#train_dataset = CrimeDataset(True)\n",
    "train = False\n",
    "test_dataset = CrimeDataset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset._labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63356b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T13:21:45.223016Z",
     "iopub.status.busy": "2024-03-18T13:21:45.222687Z",
     "iopub.status.idle": "2024-03-18T13:21:46.551732Z",
     "shell.execute_reply": "2024-03-18T13:21:46.550759Z"
    },
    "papermill": {
     "duration": 1.421088,
     "end_time": "2024-03-18T13:21:46.557862",
     "exception": false,
     "start_time": "2024-03-18T13:21:45.136774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_dataset._data[0].shape)\n",
    "plot_randomly_form_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157940e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T13:21:46.663279Z",
     "iopub.status.busy": "2024-03-18T13:21:46.662934Z",
     "iopub.status.idle": "2024-03-18T13:21:46.667944Z",
     "shell.execute_reply": "2024-03-18T13:21:46.667044Z"
    },
    "papermill": {
     "duration": 0.060875,
     "end_time": "2024-03-18T13:21:46.669971",
     "exception": false,
     "start_time": "2024-03-18T13:21:46.609096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "# print(len(train_dataset._data))\n",
    "# print(len(train_dataset._labels))\n",
    "print(train_dataset._data[0].shape)\n",
    "print(train_dataset[0][1])\n",
    "print(train_dataset[3][0].shape)\n",
    "plot_sequence_form_dataset(train_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d547f-2fb8-493a-a438-1dd0fc4036ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6bf2e37",
   "metadata": {
    "papermill": {
     "duration": 0.049683,
     "end_time": "2024-03-18T13:21:46.769625",
     "exception": false,
     "start_time": "2024-03-18T13:21:46.719942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88ce1691-5967-4452-b963-524fb747d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnum = 0\n",
    "convadd = 0\n",
    "convin = []\n",
    "convint = []\n",
    "convoup = []\n",
    "convkernel = []\n",
    "convstrid = []\n",
    "convpadding = []\n",
    "convgroup = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b31ec59",
   "metadata": {
    "papermill": {
     "duration": 0.064385,
     "end_time": "2024-03-18T13:21:46.884020",
     "exception": false,
     "start_time": "2024-03-18T13:21:46.819635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Mapping, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_divisible(\n",
    "        value: float,\n",
    "        divisor: int,\n",
    "        min_value: Optional[float] = None,\n",
    "        round_down_protect: bool = True,\n",
    "    ) -> int:\n",
    "    \"\"\"\n",
    "    This function is copied from here \n",
    "    \"https://github.com/tensorflow/models/blob/master/official/vision/modeling/layers/nn_layers.py\"\n",
    "    \n",
    "    This is to ensure that all layers have channels that are divisible by 8.\n",
    "\n",
    "    Args:\n",
    "        value: A `float` of original value.\n",
    "        divisor: An `int` of the divisor that need to be checked upon.\n",
    "        min_value: A `float` of  minimum value threshold.\n",
    "        round_down_protect: A `bool` indicating whether round down more than 10%\n",
    "        will be allowed.\n",
    "\n",
    "    Returns:\n",
    "        The adjusted value in `int` that is divisible against divisor.\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_value = max(min_value, int(value + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if round_down_protect and new_value < 0.9 * value:\n",
    "        new_value += divisor\n",
    "    return int(new_value)\n",
    "\n",
    "def conv_2d(inp, oup, kernel_size=3, stride=1, groups=1, bias=False, norm=True, act=True):\n",
    "    conv = nn.Sequential()\n",
    "    padding = (kernel_size - 1) // 2\n",
    "    conv.add_module('conv', nn.Conv3d(inp, oup, kernel_size, stride, padding, bias=bias, groups=groups))\n",
    "    if norm:\n",
    "        conv.add_module('BatchNorm2d', nn.BatchNorm3d(oup))\n",
    "    if act:\n",
    "        conv.add_module('Activation', nn.ReLU6())\n",
    "    convint.append(inp)\n",
    "    convoup.append(oup)\n",
    "    convkernel.append(kernel_size)\n",
    "    convstrid.append(stride)\n",
    "    convpadding.append(padding)\n",
    "    convgroup.append(groups)\n",
    "    #convnum += 1\n",
    "    \n",
    "    return conv\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, act=False, squeeze_excitation=False):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.block = nn.Sequential()\n",
    "        if expand_ratio != 1:\n",
    "            self.block.add_module('exp_1x1', conv_2d(inp, hidden_dim, kernel_size=3, stride=stride))\n",
    "        if squeeze_excitation:\n",
    "            self.block.add_module('conv_3x3', conv_2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, groups=hidden_dim))\n",
    "        self.block.add_module('red_1x1', conv_2d(hidden_dim, oup, kernel_size=1, stride=1, act=act))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "\n",
    "class UniversalInvertedBottleneckBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "            inp, \n",
    "            oup, \n",
    "            start_dw_kernel_size, \n",
    "            middle_dw_kernel_size, \n",
    "            middle_dw_downsample,\n",
    "            stride,\n",
    "            expand_ratio\n",
    "        ):\n",
    "        \"\"\"An inverted bottleneck block with optional depthwises.\n",
    "        Referenced from here https://github.com/tensorflow/models/blob/master/official/vision/modeling/layers/nn_blocks.py\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Starting depthwise conv.\n",
    "        self.start_dw_kernel_size = start_dw_kernel_size\n",
    "        if self.start_dw_kernel_size:            \n",
    "            stride_ = stride if not middle_dw_downsample else 1\n",
    "            self._start_dw_ = conv_2d(inp, inp, kernel_size=start_dw_kernel_size, stride=stride_, groups=inp, act=False)\n",
    "        # Expansion with 1x1 convs.\n",
    "        expand_filters = make_divisible(inp * expand_ratio, 8)\n",
    "        self._expand_conv = conv_2d(inp, expand_filters, kernel_size=1)\n",
    "        # Middle depthwise conv.\n",
    "        self.middle_dw_kernel_size = middle_dw_kernel_size\n",
    "        if self.middle_dw_kernel_size:\n",
    "            stride_ = stride if middle_dw_downsample else 1\n",
    "            self._middle_dw = conv_2d(expand_filters, expand_filters, kernel_size=middle_dw_kernel_size, stride=stride_, groups=expand_filters)\n",
    "        # Projection with 1x1 convs.\n",
    "        self._proj_conv = conv_2d(expand_filters, oup, kernel_size=1, stride=1, act=False)\n",
    "        \n",
    "        # Ending depthwise conv.\n",
    "        # this not used\n",
    "        # _end_dw_kernel_size = 0\n",
    "        # self._end_dw = conv_2d(oup, oup, kernel_size=_end_dw_kernel_size, stride=stride, groups=inp, act=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.start_dw_kernel_size:\n",
    "            x = self._start_dw_(x)\n",
    "            # print(\"_start_dw_\", x.shape)\n",
    "        x = self._expand_conv(x)\n",
    "        # print(\"_expand_conv\", x.shape)\n",
    "        if self.middle_dw_kernel_size:\n",
    "            x = self._middle_dw(x)\n",
    "            # print(\"_middle_dw\", x.shape)\n",
    "        x = self._proj_conv(x)\n",
    "        # print(\"_proj_conv\", x.shape)\n",
    "        return x\n",
    "\n",
    "class MultiQueryAttentionLayerWithDownSampling(nn.Module):\n",
    "    def __init__(self, inp, num_heads, key_dim, value_dim, query_h_strides, query_w_strides, kv_strides, dw_kernel_size=3, dropout=0.0):\n",
    "        \"\"\"Multi Query Attention with spatial downsampling.\n",
    "        Referenced from here https://github.com/tensorflow/models/blob/master/official/vision/modeling/layers/nn_blocks.py\n",
    "\n",
    "        3 parameters are introduced for the spatial downsampling:\n",
    "        1. kv_strides: downsampling factor on Key and Values only.\n",
    "        2. query_h_strides: vertical strides on Query only.\n",
    "        3. query_w_strides: horizontal strides on Query only.\n",
    "\n",
    "        This is an optimized version.\n",
    "        1. Projections in Attention is explict written out as 1x1 Conv2D.\n",
    "        2. Additional reshapes are introduced to bring a up to 3x speed up.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.value_dim = value_dim\n",
    "        self.query_h_strides = query_h_strides\n",
    "        self.query_w_strides = query_w_strides\n",
    "        self.kv_strides = kv_strides\n",
    "        self.dw_kernel_size = dw_kernel_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.head_dim = key_dim // num_heads\n",
    "\n",
    "        if self.query_h_strides > 1 or self.query_w_strides > 1:\n",
    "            self._query_downsampling_norm = nn.BatchNorm2d(inp)\n",
    "        self._query_proj = conv_2d(inp, num_heads*key_dim, 1, 1, norm=False, act=False)\n",
    "        \n",
    "        if self.kv_strides > 1:\n",
    "            self._key_dw_conv = conv_2d(inp, inp, dw_kernel_size, kv_strides, groups=inp, norm=True, act=False)\n",
    "            self._value_dw_conv = conv_2d(inp, inp, dw_kernel_size, kv_strides, groups=inp, norm=True, act=False)\n",
    "        self._key_proj = conv_2d(inp, key_dim, 1, 1, norm=False, act=False)\n",
    "        self._value_proj = conv_2d(inp, key_dim, 1, 1, norm=False, act=False)\n",
    "\n",
    "        self._output_proj = conv_2d(num_heads*key_dim, inp, 1, 1, norm=False, act=False)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _, _ = x.size()\n",
    "        if self.query_h_strides > 1 or self.query_w_strides > 1:\n",
    "            q = F.avg_pool2d(self.query_h_stride, self.query_w_stride)\n",
    "            q = self._query_downsampling_norm(q)\n",
    "            q = self._query_proj(q)\n",
    "        else:\n",
    "            q = self._query_proj(x)\n",
    "        px = q.size(2)\n",
    "        q = q.view(batch_size, self.num_heads, -1, self.key_dim) # [batch_size, num_heads, seq_length, key_dim]\n",
    "\n",
    "        if self.kv_strides > 1:\n",
    "            k = self._key_dw_conv(x)\n",
    "            k = self._key_proj(k)\n",
    "            v = self._value_dw_conv(x)\n",
    "            v = self._value_proj(v)          \n",
    "        else:\n",
    "            k = self._key_proj(x)\n",
    "            v = self._value_proj(x)\n",
    "        k = k.view(batch_size, 1, self.key_dim, -1) # [batch_size, 1, key_dim, seq_length]\n",
    "        v = v.view(batch_size, 1, -1, self.key_dim) # [batch_size, 1, seq_length, key_dim]\n",
    "\n",
    "        # calculate attn score\n",
    "        attn_score = torch.matmul(q, k) / (self.head_dim ** 0.5)\n",
    "        attn_score = self.dropout(attn_score)\n",
    "        attn_score = F.softmax(attn_score, dim=-1)\n",
    "\n",
    "        context = torch.matmul(attn_score, v)\n",
    "        context = context.view(batch_size, self.num_heads * self.key_dim, px, px)\n",
    "        output = self._output_proj(context)\n",
    "        return output\n",
    "\n",
    "class MNV4LayerScale(nn.Module):\n",
    "    def __init__(self, inp, init_value):\n",
    "        \"\"\"LayerScale as introduced in CaiT: https://arxiv.org/abs/2103.17239\n",
    "        Referenced from here https://github.com/tensorflow/models/blob/master/official/vision/modeling/layers/nn_blocks.py\n",
    "        \n",
    "        As used in MobileNetV4.\n",
    "\n",
    "        Attributes:\n",
    "            init_value (float): value to initialize the diagonal matrix of LayerScale.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.init_value = init_value\n",
    "        self._gamma = nn.Parameter(self.init_value * torch.ones(inp, 1, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self._gamma\n",
    "\n",
    "class MultiHeadSelfAttentionBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            inp,\n",
    "            num_heads, \n",
    "            key_dim,  \n",
    "            value_dim, \n",
    "            query_h_strides, \n",
    "            query_w_strides, \n",
    "            kv_strides,\n",
    "            use_layer_scale,\n",
    "            use_multi_query, \n",
    "            use_residual = True\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.query_h_strides = query_h_strides\n",
    "        self.query_w_strides = query_w_strides\n",
    "        self.kv_strides = kv_strides\n",
    "        self.use_layer_scale = use_layer_scale\n",
    "        self.use_multi_query = use_multi_query\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        self._input_norm = nn.BatchNorm2d(inp)\n",
    "        if self.use_multi_query:\n",
    "            self.multi_query_attention = MultiQueryAttentionLayerWithDownSampling(\n",
    "                inp, num_heads, key_dim, value_dim, query_h_strides, query_w_strides, kv_strides\n",
    "            )\n",
    "        else:\n",
    "            self.multi_head_attention = nn.MultiheadAttention(inp, num_heads, kdim=key_dim)\n",
    "        \n",
    "        if self.use_layer_scale:\n",
    "            self.layer_scale_init_value = 1e-5\n",
    "            self.layer_scale = MNV4LayerScale(inp, self.layer_scale_init_value) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Not using CPE, skipped\n",
    "        # input norm\n",
    "        shortcut = x\n",
    "        x = self._input_norm(x)\n",
    "        # multi query\n",
    "        if self.use_multi_query:\n",
    "            x = self.multi_query_attention(x)\n",
    "        else:\n",
    "            x = self.multi_head_attention(x, x)\n",
    "        # layer scale\n",
    "        if self.use_layer_scale:\n",
    "            x = self.layer_scale(x)\n",
    "        # use residual\n",
    "        if self.use_residual:\n",
    "            x = x + shortcut\n",
    "        return x\n",
    "\n",
    "def build_blocks(layer_spec):\n",
    "    if not layer_spec.get('block_name'):\n",
    "        return nn.Sequential()\n",
    "    block_names = layer_spec['block_name']\n",
    "    layers = nn.Sequential()\n",
    "    if block_names == \"convbn\":\n",
    "        schema_ = ['inp', 'oup', 'kernel_size', 'stride']\n",
    "        for i in range(layer_spec['num_blocks']):\n",
    "            args = dict(zip(schema_, layer_spec['block_specs'][i]))\n",
    "            layers.add_module(f\"convbn_{i}\", conv_2d(**args))\n",
    "    elif block_names == \"uib\":\n",
    "        schema_ =  ['inp', 'oup', 'start_dw_kernel_size', 'middle_dw_kernel_size', 'middle_dw_downsample', 'stride', 'expand_ratio', 'mhsa']\n",
    "        for i in range(layer_spec['num_blocks']):\n",
    "            args = dict(zip(schema_, layer_spec['block_specs'][i]))\n",
    "            mhsa = args.pop(\"mhsa\") if \"mhsa\" in args else 0\n",
    "            layers.add_module(f\"uib_{i}\", UniversalInvertedBottleneckBlock(**args))\n",
    "            if mhsa:\n",
    "                mhsa_schema_ = [\n",
    "                    \"inp\", \"num_heads\", \"key_dim\", \"value_dim\", \"query_h_strides\", \"query_w_strides\", \"kv_strides\", \n",
    "                    \"use_layer_scale\", \"use_multi_query\", \"use_residual\"\n",
    "                ]\n",
    "                args = dict(zip(mhsa_schema_, [args['oup']] + (mhsa)))\n",
    "                layers.add_module(f\"mhsa_{i}\", MultiHeadSelfAttentionBlock(**args))\n",
    "    elif block_names == \"fused_ib\":\n",
    "        schema_ = ['inp', 'oup', 'stride', 'expand_ratio', 'act']\n",
    "        for i in range(layer_spec['num_blocks']):\n",
    "            args = dict(zip(schema_, layer_spec['block_specs'][i]))\n",
    "            layers.add_module(f\"fused_ib_{i}\", InvertedResidual(**args))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return layers\n",
    "\n",
    "\n",
    "class MobileNetV4(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        # MobileNetV4ConvSmall  MobileNetV4ConvMedium  MobileNetV4ConvLarge\n",
    "        # MobileNetV4HybridMedium  MobileNetV4HybridLarge\n",
    "        \"\"\"Params to initiate MobilenNetV4\n",
    "        Args:\n",
    "            model : support 5 types of models as indicated in \n",
    "            \"https://github.com/tensorflow/models/blob/master/official/vision/modeling/backbones/mobilenet.py\"        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert model in MODEL_SPECS.keys()\n",
    "        self.model = model\n",
    "        self.spec = MODEL_SPECS[self.model]\n",
    "       \n",
    "        # conv0\n",
    "        self.conv0 = build_blocks(self.spec['conv0'])\n",
    "        # layer1\n",
    "        self.layer1 = build_blocks(self.spec['layer1'])\n",
    "        # layer2\n",
    "        self.layer2 = build_blocks(self.spec['layer2'])\n",
    "        # layer3\n",
    "        self.layer3 = build_blocks(self.spec['layer3'])\n",
    "        # layer4\n",
    "        self.layer4 = build_blocks(self.spec['layer4'])\n",
    "        # layer5   \n",
    "        self.layer5 = build_blocks(self.spec['layer5'])       \n",
    "               \n",
    "    def forward(self, x):\n",
    "        x0 = self.conv0(x)\n",
    "        print(\"conv2d\", x0.shape)\n",
    "        x1 = self.layer1(x0)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        x5 = self.layer5(x4)\n",
    "        x5 = nn.functional.adaptive_avg_pool2d(x5, 1 )\n",
    "        return [x1, x2, x3, x4, x5]\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "faf8c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MNV4ConvSmall_BLOCK_SPECS = {\n",
    "    \"conv0\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [1, 32, 3, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer1\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [32, 32, 3, 2],\n",
    "            [32, 32, 1, 1]\n",
    "        ]\n",
    "    },\n",
    "    \"layer2\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [32, 96, 3, 2],\n",
    "            [96, 64, 1, 1]\n",
    "        ]\n",
    "    },\n",
    "    \"layer3\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 6,\n",
    "        \"block_specs\": [\n",
    "            [64, 96, 5, 5, True, 2, 3],\n",
    "            [96, 96, 0, 3, True, 1, 2],\n",
    "            [96, 96, 0, 3, True, 1, 2],\n",
    "            [96, 96, 0, 3, True, 1, 2],\n",
    "            [96, 96, 0, 3, True, 1, 2],\n",
    "            [96, 96, 3, 0, True, 1, 4],\n",
    "        ]\n",
    "    },\n",
    "    \"layer4\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 6,\n",
    "        \"block_specs\": [\n",
    "            [96,  128, 3, 3, True, 2, 6],\n",
    "            [128, 128, 5, 5, True, 1, 4],\n",
    "            [128, 128, 0, 5, True, 1, 4],\n",
    "            [128, 128, 0, 5, True, 1, 3],\n",
    "            [128, 128, 0, 3, True, 1, 4],\n",
    "            [128, 128, 0, 3, True, 1, 4],\n",
    "        ]\n",
    "    },  \n",
    "    \"layer5\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [128, 960, 1, 1],\n",
    "            [960, 1280, 1, 1]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "MNV4ConvMedium_BLOCK_SPECS = {\n",
    "    \"conv0\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [1, 32, 3, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer1\": {\n",
    "        \"block_name\": \"fused_ib\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [32, 48, 2, 4.0, True]\n",
    "        ]\n",
    "    },\n",
    "    \"layer2\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [48, 80, 3, 5, True, 2, 4],\n",
    "            [80, 80, 3, 3, True, 1, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer3\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 8,\n",
    "        \"block_specs\": [\n",
    "            [80,  160, 3, 5, True, 2, 6],\n",
    "            [160, 160, 3, 3, True, 1, 4],\n",
    "            [160, 160, 3, 3, True, 1, 4],\n",
    "            [160, 160, 3, 5, True, 1, 4],\n",
    "            [160, 160, 3, 3, True, 1, 4],\n",
    "            [160, 160, 3, 0, True, 1, 4],\n",
    "            [160, 160, 0, 0, True, 1, 2],\n",
    "            [160, 160, 3, 0, True, 1, 4]\n",
    "        ]\n",
    "    },\n",
    "    \"layer4\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 11,\n",
    "        \"block_specs\": [\n",
    "            [160, 256, 5, 5, True, 2, 6],\n",
    "            [256, 256, 5, 5, True, 1, 4],\n",
    "            [256, 256, 3, 5, True, 1, 4],\n",
    "            [256, 256, 3, 5, True, 1, 4],\n",
    "            [256, 256, 0, 0, True, 1, 4],\n",
    "            [256, 256, 3, 0, True, 1, 4],\n",
    "            [256, 256, 3, 5, True, 1, 2],\n",
    "            [256, 256, 5, 5, True, 1, 4],\n",
    "            [256, 256, 0, 0, True, 1, 4],\n",
    "            [256, 256, 0, 0, True, 1, 4],\n",
    "            [256, 256, 5, 0, True, 1, 2]\n",
    "        ]\n",
    "    },  \n",
    "    \"layer5\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [256, 960, 1, 1],\n",
    "            [960, 1280, 1, 1]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "MNV4ConvLarge_BLOCK_SPECS = {\n",
    "    \"conv0\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [1, 24, 3, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer1\": {\n",
    "        \"block_name\": \"fused_ib\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [24, 48, 2, 4.0, True]\n",
    "        ]\n",
    "    },\n",
    "    \"layer2\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [48, 96, 3, 5, True, 2, 4],\n",
    "            [96, 96, 3, 3, True, 1, 4]\n",
    "        ]\n",
    "    },\n",
    "    \"layer3\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 11,\n",
    "        \"block_specs\": [\n",
    "            [96,  192, 3, 5, True, 2, 4],\n",
    "            [192, 192, 3, 3, True, 1, 4],\n",
    "            [192, 192, 3, 3, True, 1, 4],\n",
    "            [192, 192, 3, 3, True, 1, 4],\n",
    "            [192, 192, 3, 5, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4],\n",
    "            [192, 192, 3, 0, True, 1, 4]\n",
    "        ]\n",
    "    },\n",
    "    \"layer4\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 13,\n",
    "        \"block_specs\": [\n",
    "            [192, 512, 5, 5, True, 2, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 3, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 3, True, 1, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4]\n",
    "        ]\n",
    "    },  \n",
    "    \"layer5\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [512, 960, 1, 1],\n",
    "            [960, 1280, 1, 1]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def mhsa(num_heads, key_dim, value_dim, px):\n",
    "    if px == 24:\n",
    "        kv_strides = 2\n",
    "    elif px == 12:\n",
    "        kv_strides = 1\n",
    "    query_h_strides = 1 \n",
    "    query_w_strides = 1 \n",
    "    use_layer_scale = True \n",
    "    use_multi_query = True\n",
    "    use_residual = True\n",
    "    return [\n",
    "        num_heads, key_dim, value_dim, query_h_strides, query_w_strides, kv_strides, \n",
    "        use_layer_scale, use_multi_query, use_residual\n",
    "    ]\n",
    "\n",
    "MNV4HybridConvMedium_BLOCK_SPECS = {\n",
    "    \"conv0\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [3, 32, 3, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer1\": {\n",
    "        \"block_name\": \"fused_ib\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [32, 48, 2, 4.0, True]\n",
    "        ]\n",
    "    },\n",
    "    \"layer2\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [48, 80, 3, 5, True, 2, 4],\n",
    "            [80, 80, 3, 3, True, 1, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer3\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 8,\n",
    "        \"block_specs\": [\n",
    "            [80,  160, 3, 5, True, 2, 6],\n",
    "            [160, 160, 0, 0, True, 1, 2],\n",
    "            [160, 160, 3, 3, True, 1, 4],\n",
    "            [160, 160, 3, 5, True, 1, 4, mhsa(4, 64, 64, 24)],\n",
    "            [160, 160, 3, 3, True, 1, 4, mhsa(4, 64, 64, 24)],\n",
    "            [160, 160, 3, 0, True, 1, 4, mhsa(4, 64, 64, 24)],\n",
    "            [160, 160, 3, 3, True, 1, 4, mhsa(4, 64, 64, 24)],\n",
    "            [160, 160, 3, 0, True, 1, 4]\n",
    "        ]\n",
    "    },\n",
    "    \"layer4\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 12,\n",
    "        \"block_specs\": [\n",
    "            [160, 256, 5, 5, True, 2, 6],\n",
    "            [256, 256, 5, 5, True, 1, 4],\n",
    "            [256, 256, 3, 5, True, 1, 4],\n",
    "            [256, 256, 3, 5, True, 1, 4],\n",
    "            [256, 256, 0, 0, True, 1, 2],\n",
    "            [256, 256, 3, 5, True, 1, 2],\n",
    "            [256, 256, 0, 0, True, 1, 2],\n",
    "            [256, 256, 0, 0, True, 1, 4, mhsa(4, 64, 64, 12)],\n",
    "            [256, 256, 3, 0, True, 1, 4, mhsa(4, 64, 64, 12)],\n",
    "            [256, 256, 5, 5, True, 1, 4, mhsa(4, 64, 64, 12)],\n",
    "            [256, 256, 5, 0, True, 1, 4, mhsa(4, 64, 64, 12)],\n",
    "            [256, 256, 5, 0, True, 1, 4]\n",
    "        ]\n",
    "    },  \n",
    "    \"layer5\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [256, 960, 1, 1],\n",
    "            [960, 1280, 1, 1]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "MNV4HybridConvLarge_BLOCK_SPECS = {\n",
    "    \"conv0\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [3, 24, 3, 2]\n",
    "        ]\n",
    "    },\n",
    "    \"layer1\": {\n",
    "        \"block_name\": \"fused_ib\",\n",
    "        \"num_blocks\": 1,\n",
    "        \"block_specs\": [\n",
    "            [24, 48, 2, 4.0, True]\n",
    "        ]\n",
    "    },\n",
    "    \"layer2\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [48, 96, 3, 5, True, 2, 4],\n",
    "            [96, 96, 3, 3, True, 1, 4]\n",
    "        ]\n",
    "    },\n",
    "    \"layer3\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 11,\n",
    "        \"block_specs\": [\n",
    "            [96,  192, 3, 5, True, 2, 4],\n",
    "            [192, 192, 3, 3, True, 1, 4],\n",
    "            [192, 192, 3, 3, True, 1, 4],\n",
    "            [192, 192, 3, 3, True, 1, 4],\n",
    "            [192, 192, 3, 5, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4],\n",
    "            [192, 192, 5, 3, True, 1, 4, mhsa(8, 48, 48, 24)],\n",
    "            [192, 192, 5, 3, True, 1, 4, mhsa(8, 48, 48, 24)],\n",
    "            [192, 192, 5, 3, True, 1, 4, mhsa(8, 48, 48, 24)],\n",
    "            [192, 192, 5, 3, True, 1, 4, mhsa(8, 48, 48, 24)],\n",
    "            [192, 192, 3, 0, True, 1, 4]\n",
    "        ]\n",
    "    },\n",
    "    \"layer4\": {\n",
    "        \"block_name\": \"uib\",\n",
    "        \"num_blocks\": 14,\n",
    "        \"block_specs\": [\n",
    "            [192, 512, 5, 5, True, 2, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 3, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 0, True, 1, 4],\n",
    "            [512, 512, 5, 3, True, 1, 4],\n",
    "            [512, 512, 5, 5, True, 1, 4, mhsa(8, 64, 64, 12)],\n",
    "            [512, 512, 5, 0, True, 1, 4, mhsa(8, 64, 64, 12)],\n",
    "            [512, 512, 5, 0, True, 1, 4, mhsa(8, 64, 64, 12)],\n",
    "            [512, 512, 5, 0, True, 1, 4, mhsa(8, 64, 64, 12)],\n",
    "            [512, 512, 5, 0, True, 1, 4]\n",
    "        ]\n",
    "    },  \n",
    "    \"layer5\": {\n",
    "        \"block_name\": \"convbn\",\n",
    "        \"num_blocks\": 2,\n",
    "        \"block_specs\": [\n",
    "            [512, 960, 1, 1],\n",
    "            [960, 1280, 1, 1]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"MobileNetV4ConvSmall\": MNV4ConvSmall_BLOCK_SPECS,\n",
    "    \"MobileNetV4ConvMedium\": MNV4ConvMedium_BLOCK_SPECS,\n",
    "    \"MobileNetV4ConvLarge\": MNV4ConvLarge_BLOCK_SPECS,\n",
    "    \"MobileNetV4HybridMedium\": MNV4HybridConvMedium_BLOCK_SPECS,\n",
    "    \"MobileNetV4HybridLarge\": MNV4HybridConvLarge_BLOCK_SPECS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52d75303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2792032\n",
      "Check output shape ...\n",
      "conv2d torch.Size([4, 32, 5, 112, 112])\n",
      "torch.Size([4, 32, 3, 56, 56])\n",
      "torch.Size([4, 64, 2, 28, 28])\n",
      "torch.Size([4, 96, 1, 14, 14])\n",
      "torch.Size([4, 128, 1, 7, 7])\n",
      "torch.Size([4, 1280, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "convnum = 0\n",
    "convadd = 0\n",
    "convin = [64]\n",
    "convd = [9]\n",
    "convint = []\n",
    "convoup = []\n",
    "convkernel = []\n",
    "convstrid = []\n",
    "convpadding = []\n",
    "convgroup = []\n",
    "\n",
    "# Support ['MobileNetV4ConvSmall', 'MobileNetV4ConvMedium', 'MobileNetV4ConvLarge']\n",
    "# Also supported ['MobileNetV4HybridMedium', 'MobileNetV4HybridLarge']\n",
    "model = MobileNetV4(\"MobileNetV4ConvSmall\")\n",
    "\n",
    "# Check the trainable params\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "\n",
    "# Check the model's output shape\n",
    "print(\"Check output shape ...\")\n",
    "x = torch.rand(4, 1, 9, 64, 64)\n",
    "y = model(x)\n",
    "for i in y:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90bc3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_output_size(H_in, W_in, kernel_size, stride, padding, dilation=1):\n",
    "    H_out = math.floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "    W_out = math.floor((W_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "    return H_out, W_out\n",
    "\n",
    "def conv3d_output_shape(D_in, H_in, kernel_size, stride, padding, dilation=1):\n",
    "    D_out = math.floor((D_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "    H_out = math.floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "    return D_out, H_out, H_out  # D_out, H_out, W_out are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7246e39c-cada-4105-8e4f-7b9f524daa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "convin=[224]\n",
    "for i in range(len(convint)):\n",
    "    a, b, c= conv3d_output_shape(convd[i], convin[i], convkernel[i], convstrid[i], convpadding[i])\n",
    "    convd.append(a)\n",
    "    convin.append(b)\n",
    "print(len(convin))\n",
    "print(len(convkernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56cb3462-4122-4ee4-8d92-3209db5b6e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 5, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(convd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8a117b3-7ac8-4a85-9447-71b3304a395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOUT: 32\n",
      "Conv2D FLOPs: 294912\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv2d_output_shape(H_in, W_in, kernel_size, stride, padding):\n",
    "    H_out = math.floor((H_in + 2 * padding - kernel_size) / stride + 1)\n",
    "    W_out = math.floor((W_in + 2 * padding - kernel_size) / stride + 1)\n",
    "    return H_out, W_out\n",
    "def conv3d_output_shape(D_in, H_in, kernel_size, stride, padding, dilation=1):\n",
    "    D_out = math.floor((D_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "    H_out = math.floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "    return D_out, H_out, H_out  # D_out, H_out, W_out are the same\n",
    "\n",
    "def conv2d_flops(H_in, W_in, inp, oup, kernel_size, stride, groups):\n",
    "    padding = (kernel_size - 1) // 2\n",
    "    H_out, W_out = conv2d_output_shape(H_in, W_in, kernel_size, stride, padding)\n",
    "    flops = H_out * W_out * oup * kernel_size * kernel_size * (inp // groups)\n",
    "    print(\"HOUT:\", H_out)\n",
    "    return flops\n",
    "def conv3d_flops(D_in, H_in, inp, oup, kernel_size, stride, padding, groups):\n",
    "    D_out, H_out, W_out = conv3d_output_shape(D_in, H_in, kernel_size, stride, padding)\n",
    "    print(\"Dout: {}, Hout: {}\".format(D_out, H_out))\n",
    "    return D_out * H_out * W_out * oup * kernel_size * kernel_size * kernel_size * (inp // groups)\n",
    "\n",
    "# Example usage\n",
    "H_in, W_in = 64, 64  # Example input dimensions\n",
    "inp = 1              # Example input channels\n",
    "oup = 32             # Example output channels\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "groups = 1\n",
    "\n",
    "flops = conv2d_flops(H_in, W_in, inp, oup, kernel_size, stride, groups)\n",
    "print(f\"Conv2D FLOPs: {flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2bec5a1-03e8-43ed-ab30-395a469015ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0\n",
      "input Depth: 9, input demension: 224*224, input channel: 1, output channel: 32, kernel: 3, stride: 2, group: 1\n",
      "Dout: 5, Hout: 112\n",
      "54190080\n",
      "\n",
      "# 1\n",
      "input Depth: 5, input demension: 112*112, input channel: 32, output channel: 32, kernel: 3, stride: 2, group: 1\n",
      "Dout: 3, Hout: 56\n",
      "260112384\n",
      "\n",
      "# 2\n",
      "input Depth: 3, input demension: 56*56, input channel: 32, output channel: 32, kernel: 1, stride: 1, group: 0\n",
      "Dout: 3, Hout: 56\n",
      "9633792\n",
      "\n",
      "# 3\n",
      "input Depth: 3, input demension: 56*56, input channel: 32, output channel: 96, kernel: 3, stride: 2, group: 1\n",
      "Dout: 2, Hout: 28\n",
      "130056192\n",
      "\n",
      "# 4\n",
      "input Depth: 2, input demension: 28*28, input channel: 96, output channel: 64, kernel: 1, stride: 1, group: 0\n",
      "Dout: 2, Hout: 28\n",
      "9633792\n",
      "\n",
      "# 5\n",
      "input Depth: 2, input demension: 28*28, input channel: 64, output channel: 64, kernel: 5, stride: 1, group: 2\n",
      "Dout: 2, Hout: 28\n",
      "12544000\n",
      "\n",
      "# 6\n",
      "input Depth: 2, input demension: 28*28, input channel: 64, output channel: 192, kernel: 1, stride: 1, group: 0\n",
      "Dout: 2, Hout: 28\n",
      "19267584\n",
      "\n",
      "# 7\n",
      "input Depth: 2, input demension: 28*28, input channel: 192, output channel: 192, kernel: 5, stride: 2, group: 2\n",
      "Dout: 1, Hout: 14\n",
      "4704000\n",
      "\n",
      "# 8\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 96, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 9\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 192, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 10\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 192, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 14\n",
      "1016064\n",
      "\n",
      "# 11\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 96, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 12\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 192, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 13\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 192, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 14\n",
      "1016064\n",
      "\n",
      "# 14\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 96, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 15\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 192, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 16\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 192, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 14\n",
      "1016064\n",
      "\n",
      "# 17\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 96, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 18\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 192, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 19\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 192, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 14\n",
      "1016064\n",
      "\n",
      "# 20\n",
      "input Depth: 1, input demension: 14*14, input channel: 192, output channel: 96, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "3612672\n",
      "\n",
      "# 21\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 96, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 14\n",
      "508032\n",
      "\n",
      "# 22\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 384, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "7225344\n",
      "\n",
      "# 23\n",
      "input Depth: 1, input demension: 14*14, input channel: 384, output channel: 96, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "7225344\n",
      "\n",
      "# 24\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 96, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 14\n",
      "508032\n",
      "\n",
      "# 25\n",
      "input Depth: 1, input demension: 14*14, input channel: 96, output channel: 576, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 14\n",
      "10838016\n",
      "\n",
      "# 26\n",
      "input Depth: 1, input demension: 14*14, input channel: 576, output channel: 576, kernel: 3, stride: 2, group: 1\n",
      "Dout: 1, Hout: 7\n",
      "762048\n",
      "\n",
      "# 27\n",
      "input Depth: 1, input demension: 7*7, input channel: 576, output channel: 128, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3612672\n",
      "\n",
      "# 28\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 128, kernel: 5, stride: 1, group: 2\n",
      "Dout: 1, Hout: 7\n",
      "784000\n",
      "\n",
      "# 29\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 512, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 30\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 512, kernel: 5, stride: 1, group: 2\n",
      "Dout: 1, Hout: 7\n",
      "3136000\n",
      "\n",
      "# 31\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 128, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 32\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 512, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 33\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 512, kernel: 5, stride: 1, group: 2\n",
      "Dout: 1, Hout: 7\n",
      "3136000\n",
      "\n",
      "# 34\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 128, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 35\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 384, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "2408448\n",
      "\n",
      "# 36\n",
      "input Depth: 1, input demension: 7*7, input channel: 384, output channel: 384, kernel: 5, stride: 1, group: 2\n",
      "Dout: 1, Hout: 7\n",
      "2352000\n",
      "\n",
      "# 37\n",
      "input Depth: 1, input demension: 7*7, input channel: 384, output channel: 128, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "2408448\n",
      "\n",
      "# 38\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 512, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 39\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 512, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 7\n",
      "677376\n",
      "\n",
      "# 40\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 128, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 41\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 512, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 42\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 512, kernel: 3, stride: 1, group: 1\n",
      "Dout: 1, Hout: 7\n",
      "677376\n",
      "\n",
      "# 43\n",
      "input Depth: 1, input demension: 7*7, input channel: 512, output channel: 128, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "3211264\n",
      "\n",
      "# 44\n",
      "input Depth: 1, input demension: 7*7, input channel: 128, output channel: 960, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "6021120\n",
      "\n",
      "# 45\n",
      "input Depth: 1, input demension: 7*7, input channel: 960, output channel: 1280, kernel: 1, stride: 1, group: 0\n",
      "Dout: 1, Hout: 7\n",
      "60211200\n",
      "\n",
      "674901696\n"
     ]
    }
   ],
   "source": [
    "convadd = 0\n",
    "convnum = 0\n",
    "for i in range(len(convint)):\n",
    "    print('#',convnum)\n",
    "    print(\"input Depth: {0}, input demension: {1}*{1}, input channel: {2}, output channel: {3}, kernel: {4}, stride: {5}, group: {6}\".format(convd[i], convin[i], convint[i], convoup[i], convkernel[i], convstrid[i], convpadding[i], convgroup[i]))\n",
    "    flops = conv3d_flops(convd[i], convin[i], convint[i], convoup[i], convkernel[i], convstrid[i], convpadding[i], convgroup[i])\n",
    "    print(flops)\n",
    "    print()\n",
    "    convadd += flops\n",
    "    convnum+=1\n",
    "print(convadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2d8cd845-dc8a-46a1-9001-79435920e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(convint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe219b9-3dce-412e-8a87-4e20c6426797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f08b4-cd79-4b2b-a4fb-c8979634ea52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 75548,
     "sourceId": 170620,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 824.711442,
   "end_time": "2024-03-18T13:24:09.430326",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-18T13:10:24.718884",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
